{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project Proposal for CS545</h1>\n",
    "\n",
    "Sam Armstrong, Saloni Choudhary, Brandon Hua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "\n",
    "Countless people have tried to predict where stock prices will go to decide when and where to put their money. We believe that LSTMs (Long Short-Term Memory), a recurrent neural network architecture, can help us achieve that. The recurrent nature of this neural network architecture is what makes it so interesting. LSTMs are not a feedforward network but instead a feedback one.\n",
    "\n",
    "A recurrent neural network performs well if the relevant information needed is close to the place it's needed. Unfortunately, as the gap between the information needed for predicting and where it's needed increases it becomes really hard for recurrent neural networks to predict. This problem is knowns as \"long-term dependencies\". LSTM's are a special kind of recurrent neural network architecture which can solve the long-term dependencies problem.\n",
    "\n",
    "LSTM's have a cell, an input gate, output gate, and forget gate. These gates regulate the state of the cell. The first step of the network is to decide how much of the information is to be let in or thrown away which is decided by the \"forget-gate\" layer. It has a sigmoid funtion which gives a value from 0 - 1, 0 means to be thrown away. The LSTM then decides what information it wants to retain in the cell state which is done by the sigmoid function in the input gate. The sigmoid function decides which cell values needs to be updated, by creating a layer of new candidate values with the tanh function. Now, with the new values we update the values of the cell state. Next comes the decision of what values to be shown in the output. The output depends on the filtered cell state values and to make that decision, we run the sigmoid function through it to decide what needs to be outputted. Now, we place the cell state with the tanh activation function and multiply it with the output of the sigmoid function to output the desired values. \n",
    "\n",
    "This is how LSTM's work generally. In our project, we are trying to bring variations into it to seek better results. These variations include but are not limited to: data sampling, training/testing data partitioning, adjusting the hidden layers, adjusting the learning methods, adjusting the LSTM architecture, and regularization. We will also be analyzing the structure and weights of the LSTM model to help understand how it's making its descisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Methods</h2>\n",
    "\n",
    "We are using an LSTM model to predict stock prices because a regular neural network struggles with time-series data especially time-series that have random walks (e.g. stock prices). We chose stock prices because the data is easily availble and it shares a lot of properties with other types of data. Here are the steps we will follow to complete this project:\n",
    "\n",
    "1. Gather Data\n",
    "2. Build a univariate LSTM model for each stock\n",
    "3. Build a multivariate LSTM model for the stocks\n",
    "4. Optimize the models\n",
    "5. Build a univariate LSTM model with regularization for each stock\n",
    "6. Build a multivariate LSTM model with regularization for the stocks\n",
    "7. Optimize the models\n",
    "8. Compare all four models\n",
    "9. Finalize and analyze the results\n",
    "10. EXTRA incorporate other neural networks into our models like CNNs or GANs\n",
    "\n",
    "The data will be gathered from Yahoo Finance and we will be using Keras and Tensorflow's LSTM library. We will run our data with all the models, compare their results and make observations about how and why they perform better or worse. We will also mention all the measures we took to refine our models to get better results. \n",
    "    \n",
    "Sam's Work. \n",
    "1. Get data and filter/partition data\n",
    "2. Compare and help optimize models/results\n",
    "\n",
    "Saloni's Work. \n",
    "1. LSTM univariate\n",
    "2. LSTM regularization univariate\n",
    "\n",
    "Brandon's Work. \n",
    "1. LSTM multivariate\n",
    "2. LSTM regularization multivariate\n",
    "\n",
    "We will complete this by having weekly meetings where we will work and discuss the following:\n",
    "\n",
    "1. Say what we did that week\n",
    "2. Where we will plan to be by the next week\n",
    "3. How can we help each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Possible Results</h2>\n",
    "\n",
    "Stock prices are really difficult to predict and there is not a 100% accurate way of predicting them. Often the best stock price predictions are from the simpler models and Occam's Razor does apply. It will be interesting to see if the univariate models (the simpler models) or the multivariate models (the complex model) will provide better results. It will also be intersting to see if the model performs better on smaller or larger data samples. Stock price prediction models often suffer from overtraining and LSTMs often suffer from the vanishing gradient problem so it will be interesting to see if our models improve with regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Timeline</h2>\n",
    "\n",
    "| Date | Sam | Saloni | Brandon |\n",
    "| --- | --- | --- | --- |\n",
    "| 10/21/19 | Prepare Data | Setup LSTM Univariate Model | Setup LSTM Multivariate Model |\n",
    "| 10/28/19 | Write Data Partition Scripts | Fine Tune Univariate Model | Fine Tune Multivariate Model |\n",
    "| 11/4/19 | Assist/Compare Models | Setup LSTM Univariate Model's Regularization | Setup LSTM Multivariate Model's Regularization |\n",
    "| 11/11/19 | Finalize Results | Fine Tune Univariate Model with Regularization | Fine Tune Multivariate Model with Regularization |\n",
    "| 11/18/19 | Project Due |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
